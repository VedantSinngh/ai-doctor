import os
import base64
import logging
from typing import Optional, Dict, List
from datetime import datetime
from groq import Groq
from dotenv import load_dotenv
import gradio as gr
from gtts import gTTS
import speech_recognition as sr
from pydub import AudioSegment
from io import BytesIO
import json
import markdown
import pdfkit
from pathlib import Path
from xhtml2pdf import pisa

# Load environment variables
load_dotenv()

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Constants
MODEL_NAME = "meta-llama/llama-4-scout-17b-16e-instruct"
TEMP_DIR = Path("temp")
TEMP_DIR.mkdir(exist_ok=True)

# System prompts
SYSTEM_PROMPT = """You are an AI medical assistant designed to provide preliminary health information. 
When analyzing medical images or symptoms:
1. Describe what you observe in the image or from described symptoms
2. Provide possible conditions that might explain these observations
3. Suggest general self-care recommendations when appropriate
4. Always include: "I'm an AI assistant and cannot replace professional medical advice. Please consult a doctor."
5. Keep responses concise (3-4 sentences maximum)
6. Use layman's terms but maintain medical accuracy"""

CHAT_PROMPT = """You are an AI medical assistant chatting with a patient. Guidelines:
1. Be empathetic and professional
2. Ask clarifying questions if symptoms are unclear
3. Provide general health information when appropriate
4. Always remind: "Remember, I'm an AI assistant. For proper diagnosis, please consult a doctor."
5. Keep responses to 2-3 sentences maximum
6. If serious, advise immediate medical attention"""

# Initialize Groq client
try:
    client = Groq(api_key=os.environ["GROQ_API_KEY"])
except KeyError as e:
    logger.error("GROQ_API_KEY not found in environment variables")
    raise
except Exception as e:
    logger.error(f"Failed to initialize Groq client: {e}")
    raise

class MedicalAssistant:
    def __init__(self):
        self.conversation_history = []
        self.current_report = {
            "patient_info": {},
            "symptoms": [],
            "images": [],
            "diagnoses": [],
            "recommendations": [],
            "timestamp": datetime.now().isoformat(),
            "disclaimer": "This report was generated by an AI assistant and is not a substitute for professional medical advice."
        }
        self.recognizer = sr.Recognizer()
    
    def add_to_history(self, role: str, content: str):
        """Add message to conversation history"""
        self.conversation_history.append({"role": role, "content": content})
    
    def chat_response(self, user_input: str) -> str:
        """Generate response to user text input"""
        try:
            self.add_to_history("user", user_input)
            
            messages = [
                {"role": "system", "content": CHAT_PROMPT},
                *self.conversation_history[-6:]  # Keep context of last 3 exchanges
            ]
            
            response = client.chat.completions.create(
                messages=messages,
                model=MODEL_NAME,
                max_tokens=300,
                temperature=0.3
            )
            
            bot_response = response.choices[0].message.content
            
            # Ensure disclaimer is included
            if "I'm an AI assistant" not in bot_response:
                bot_response += "\n\nRemember: I'm an AI assistant and this isn't medical advice. Please consult a doctor."
            
            self.add_to_history("assistant", bot_response)
            self.current_report["symptoms"].append(user_input)
            self.current_report["recommendations"].append(bot_response)
            
            return bot_response
        
        except Exception as e:
            logger.error(f"Error in chat_response: {e}")
            return f"Sorry, I encountered an error. Please try again."

    def analyze_image(self, image_path: str, user_question: str = "") -> str:
        """Analyze a medical image with optional user question"""
        try:
            encoded_image = self.encode_image(image_path)
            if not encoded_image:
                return "Failed to process the image"
            
            self.current_report["images"].append({
                "path": image_path,
                "question": user_question
            })
            
            messages = [
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": f"{user_question}\n\nPlease analyze this medical image."},
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{encoded_image}"}},
                    ],
                }
            ]
            
            response = client.chat.completions.create(
                messages=messages,
                model=MODEL_NAME,
                max_tokens=512,
                temperature=0.2
            )
            
            bot_response = response.choices[0].message.content
            
            if "I'm an AI assistant" not in bot_response:
                bot_response += "\n\nImportant: I'm an AI assistant and cannot replace a doctor's evaluation."
            
            self.add_to_history("assistant", bot_response)
            self.current_report["diagnoses"].append(bot_response)
            
            return bot_response
        
        except Exception as e:
            logger.error(f"Error in analyze_image: {e}")
            return f"Image analysis failed. Please try again."

    @staticmethod
    def encode_image(image_path: str) -> Optional[str]:
        """Encode image to base64 string"""
        try:
            with open(image_path, "rb") as image_file:
                return base64.b64encode(image_file.read()).decode('utf-8')
        except Exception as e:
            logger.error(f"Error encoding image: {e}")
            return None

    def record_audio(self) -> Optional[str]:
        """Record audio from microphone and save to file"""
        audio_path = TEMP_DIR / "recording.mp3"
        try:
            with sr.Microphone() as source:
                self.recognizer.adjust_for_ambient_noise(source, duration=1.0)
                logger.info("Recording...")
                audio_data = self.recognizer.listen(source, timeout=15, phrase_time_limit=10)
                
                # Convert to MP3
                wav_data = audio_data.get_wav_data()
                audio_segment = AudioSegment.from_wav(BytesIO(wav_data))
                audio_segment.export(audio_path, format="mp3", bitrate="128k")
                
                return str(audio_path)
        except Exception as e:
            logger.error(f"Recording failed: {e}")
            return None

    def transcribe_audio(self, audio_path: str) -> Optional[str]:
        """Transcribe audio file to text"""
        try:
            with open(audio_path, "rb") as audio_file:
                transcription = client.audio.transcriptions.create(
                    file=audio_file,
                    model="whisper-large-v3",
                    language="en",
                    temperature=0.0
                )
            return transcription.text
        except Exception as e:
            logger.error(f"Transcription failed: {e}")
            return None

    def text_to_speech(self, text: str) -> Optional[str]:
        """Convert text to speech and save as MP3"""
        audio_path = TEMP_DIR / "response.mp3"
        try:
            tts = gTTS(text=text, lang='en', slow=False)
            tts.save(audio_path)
            return str(audio_path)
        except Exception as e:
            logger.error(f"TTS failed: {e}")
            return None

    def generate_report(self, format: str = "markdown") -> Dict:
        """Generate consultation report in specified format"""
        try:
            report_data = {
                "title": "AI Medical Consultation Report",
                "date": datetime.now().strftime("%Y-%m-%d %H:%M"),
                **self.current_report
            }
            
            if format == "markdown":
                content = self._generate_markdown(report_data)
                return {"content": content, "file_path": None}
            elif format == "pdf":
                file_path = self._generate_pdf(report_data)
                return {"content": None, "file_path": file_path}
            elif format == "json":
                content = json.dumps(report_data, indent=2)
                return {"content": content, "file_path": None}
            else:
                raise ValueError("Unsupported format")
        
        except Exception as e:
            logger.error(f"Report generation failed: {e}")
            return {"content": f"Error: {str(e)}", "file_path": None}

    def _generate_markdown(self, report_data: Dict) -> str:
        """Generate markdown formatted report"""
        md = [
            f"# {report_data['title']}",
            f"**Date:** {report_data['date']}",
            ""
        ]
        
        if report_data['symptoms']:
            md.extend([
                "## Reported Symptoms",
                *[f"- {symptom}" for symptom in report_data['symptoms']],
                ""
            ])
        
        if report_data['images']:
            md.extend([
                "## Image Analyses",
                *[f"- **{Path(img['path']).name}**: {img['question'] or 'No specific question'}" 
                  for img in report_data['images']],
                ""
            ])
        
        if report_data['diagnoses']:
            md.extend([
                "## Preliminary Assessments",
                *[f"- {d.replace('\n', '  \n')}" for d in report_data['diagnoses']],
                ""
            ])
        
        if report_data['recommendations']:
            md.extend([
                "## Recommendations",
                *[f"- {r.replace('\n', '  \n')}" for r in report_data['recommendations']],
                ""
            ])
        
        md.extend([
            "## Disclaimer",
            report_data['disclaimer']
        ])
        
        return "\n".join(md)

    def _generate_pdf(self, report_data: Dict) -> str:
        """Generate PDF report using xhtml2pdf"""
        pdf_path = str(TEMP_DIR / "medical_report.pdf")
        try:
            md_content = self._generate_markdown(report_data)
            html_content = markdown.markdown(md_content)
            
            # Create assets directory if it doesn't exist
            assets_dir = Path("assets")
            assets_dir.mkdir(exist_ok=True)
            
            # Path to verification stamp image
            stamp_path = assets_dir / "verification_stamp.png"
            
            styled_html = f"""
            <!DOCTYPE html>
            <html>
                <head>
                    <meta charset="UTF-8">
                    <title>Clinical Assessment Report</title>
                    <style>
                        @page {{
                            size: A4;
                            margin: 1.5cm;
                            @top-right {{
                                content: "Page " counter(page) " of " counter(pages);
                                font-size: 9pt;
                                color: #555;
                            }}
                        }}
                        body {{
                            font-family: "Helvetica", "Arial", sans-serif;
                            line-height: 1.5;
                            color: #222;
                            margin: 0;
                            padding: 0;
                            background-color: #fff;
                        }}
                        .header {{
                            border-bottom: 2px solid #005a87;
                            padding-bottom: 10px;
                            margin-bottom: 20px;
                            display: flex;
                            justify-content: space-between;
                            align-items: center;
                        }}
                        .logo {{
                            text-align: right;
                            font-weight: bold;
                            color: #005a87;
                            font-size: 14pt;
                        }}
                        h1 {{
                            color: #005a87;
                            margin: 0 0 5px 0;
                            font-size: 20pt;
                            font-weight: bold;
                        }}
                        .report-info {{
                            background-color: #f8f8f8;
                            border-left: 4px solid #005a87;
                            padding: 10px 15px;
                            margin-bottom: 20px;
                        }}
                        .report-meta {{
                            display: flex;
                            justify-content: space-between;
                            font-size: 10pt;
                            color: #444;
                        }}
                        h2 {{
                            color: #005a87;
                            font-size: 14pt;
                            margin-top: 25px;
                            margin-bottom: 10px;
                            padding-bottom: 5px;
                            border-bottom: 1px solid #ddd;
                        }}
                        ul {{
                            margin: 10px 0;
                            padding-left: 20px;
                        }}
                        li {{
                            margin-bottom: 8px;
                            line-height: 1.4;
                        }}
                        .section {{
                        margin-bottom: 20px;
                    }}
                    .disclaimer {{
                        margin-top: 30px;
                        padding: 15px;
                        border: 1px solid #eaeaea;
                        border-left: 4px solid #c0392b;
                        background-color: #fdf7f7;
                        font-size: 9pt;
                        color: #555;
                    }}
                    .verification {{
                        display: flex;
                        justify-content: space-between;
                        align-items: center;
                        margin-top: 40px;
                        border-top: 1px solid #eaeaea;
                        padding-top: 15px;
                    }}
                    .verification-info {{
                        font-size: 9pt;
                        color: #555;
                    }}
                    .verification-stamp {{
                        width: 100px;
                        height: 100px;
                        opacity: 0.85;
                    }}
                    .caduceus {{
                        font-size: 24pt;
                        color: #005a87;
                        margin-right: 10px;
                    }}
                    table {{
                        width: 100%;
                        border-collapse: collapse;
                        margin: 15px 0;
                    }}
                    th {{
                        background-color: #f0f7fb;
                        color: #005a87;
                        text-align: left;
                        padding: 8px;
                        border-bottom: 2px solid #ddd;
                        font-weight: bold;
                    }}
                    td {{
                        padding: 8px;
                        border-bottom: 1px solid #eee;
                    }}
                    tr:nth-child(even) {{
                        background-color: #f9f9f9;
                    }}
                    .patient-id {{
                        font-family: monospace;
                        background-color: #f0f7fb;
                        padding: 3px 5px;
                        border-radius: 3px;
                        font-size: 9pt;
                    }}
                </style>
            </head>
            <body>
                <div class="header">
                    <div>
                        <h1>Clinical Assessment Report</h1>
                        <div>AI Medical Consultation System</div>
                    </div>
                    <div class="logo">
                        <span class="caduceus">⚕</span> MedAI
                    </div>
                </div>
                
                <div class="report-info">
                    <div class="report-meta">
                        <div><strong>Report Date:</strong> {report_data['date']}</div>
                        <div><strong>Report ID:</strong> <span class="patient-id">MED-{datetime.now().strftime('%Y%m%d')}-{hash(report_data['date']) % 10000:04d}</span></div>
                    </div>
                </div>
                
                <div class="section">
                    {html_content}
                </div>
                
                <div class="disclaimer">
                    <strong>IMPORTANT DISCLAIMER:</strong> This report was generated by an AI medical assistant and is not a substitute for professional medical advice, diagnosis, or treatment. Always seek the advice of your physician or other qualified health provider with any questions you may have regarding a medical condition.
                </div>
                
                <div class="verification">
                    <div class="verification-info">
                        <p><strong>Verification Code:</strong> {hash(report_data['timestamp'])%100000:05d}-{hash(report_data['date'])%1000:03d}-AI</p>
                        <p>Generated on {datetime.now().strftime('%Y-%m-%d at %H:%M:%S')}</p>
                        <p>This document is digitally generated and does not require a signature.</p>
                    </div>
                    <div>
                        <img class="verification-stamp" src="{str(stamp_path)}" alt="Verification Stamp">
                    </div>
                </div>
            </body>
        </html>
        """
        
        with open(pdf_path, "wb") as pdf_file:
            pisa_status = pisa.CreatePDF(
                styled_html,
                dest=pdf_file,
                encoding='UTF-8'
            )
        
        if pisa_status.err:
            raise RuntimeError("PDF generation failed")
            
        return pdf_path
    except Exception as e:
        logger.error(f"PDF generation failed: {e}")
        raise

def create_gradio_interface():
    """Create and configure Gradio interface"""
    assistant = MedicalAssistant()
    
    with gr.Blocks(title="AI Doctor", theme=gr.themes.Soft()) as app:
        gr.Markdown("# 🩺 AI Medical Assistant")
        gr.Markdown("Describe your symptoms or upload an image for preliminary assessment")
        
        with gr.Row():
            with gr.Column(scale=2):
                chatbot = gr.Chatbot(label="Conversation", height=400)
                msg = gr.Textbox(label="Your message", placeholder="Describe your symptoms...")
                
                with gr.Row():
                    record_btn = gr.Button("🎤 Record Voice")
                    audio_output = gr.Audio(visible=False)
                    image_input = gr.Image(type="filepath", label="Upload medical image")
                
                submit_btn = gr.Button("Submit", variant="primary")
            
            with gr.Column(scale=1):
                with gr.Tab("Report"):
                    report_format = gr.Radio(
                        ["markdown", "pdf", "json"],
                        label="Report Format",
                        value="markdown"
                    )
                    generate_btn = gr.Button("Generate Report")
                    report_output = gr.Markdown(label="Report Preview")
                    report_download = gr.File(label="Download Report", visible=False)
                
                with gr.Tab("Audio Response"):
                    tts_btn = gr.Button("🔊 Generate Voice Response")
                    tts_output = gr.Audio(label="Doctor's Response", interactive=False)
        
        # Event handlers
        def respond(message: str, image: Optional[str], history: List):
            if not message and not image:
                return history, "Please provide symptoms or an image"
            
            if image:
                response = assistant.analyze_image(image, message)
            else:
                response = assistant.chat_response(message)
            
            history.append((message, response))
            return history, ""
        
        def record_audio():
            audio_path = assistant.record_audio()
            if audio_path:
                transcription = assistant.transcribe_audio(audio_path)
                return audio_path, transcription
            return None, "Recording failed"
        
        def generate_report(format: str):
            report = assistant.generate_report(format)
            if format == "pdf":
                return None, report["file_path"], gr.File(visible=True)
            return report["content"], None, gr.File(visible=False)
        
        def generate_tts_response(history: List):
            if not history:
                return None
            last_response = history[-1][1]
            audio_path = assistant.text_to_speech(last_response)
            return audio_path if audio_path else None
        
        # Connect components
        msg.submit(
            respond,
            [msg, image_input, chatbot],
            [chatbot, msg]
        )
        
        submit_btn.click(
            respond,
            [msg, image_input, chatbot],
            [chatbot, msg]
        )
        
        record_btn.click(
            record_audio,
            outputs=[audio_output, msg]
        )
        
        generate_btn.click(
            generate_report,
            inputs=report_format,
            outputs=[report_output, report_download, report_download]
        )
        
        tts_btn.click(
            generate_tts_response,
            inputs=chatbot,
            outputs=tts_output
        )
    
    return app

if __name__ == "__main__":
    # Check required environment variables
    if "GROQ_API_KEY" not in os.environ:
        logger.error("GROQ_API_KEY environment variable not found")
        raise ValueError("Please set GROQ_API_KEY in your .env file")
    
    # Create and launch interface
    interface = create_gradio_interface()
    
    # Launch with explicit localhost URL in the printed message
    print("\nApplication will be available at: http://127.0.0.1:7860")
    print("Press Ctrl+C to stop the server\n")
    
    interface.launch(
        server_name="0.0.0.0",  # Bind to all network interfaces
        server_port=7860,
        share=False,  # Set to True if you want a public gradio.link
        show_error=True
    )